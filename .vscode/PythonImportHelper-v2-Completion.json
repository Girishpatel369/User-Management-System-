[
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "imutils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imutils",
        "description": "imutils",
        "detail": "imutils",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "pytesseract",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytesseract",
        "description": "pytesseract",
        "detail": "pytesseract",
        "documentation": {}
    },
    {
        "label": "tkinter",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tkinter",
        "description": "tkinter",
        "detail": "tkinter",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageTk",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "pyttsx3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyttsx3",
        "description": "pyttsx3",
        "detail": "pyttsx3",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "helmet_or_nohelmet",
        "kind": 2,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "def helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)\n        helmet_roi = helmet_roi/255.0\n        return int(model.predict(helmet_roi)[0][0])\n    except:\n        pass\ndef extract_number_plate_text(image):",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "extract_number_plate_text",
        "kind": 2,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "def extract_number_plate_text(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # Perform preprocessing (like thresholding, adaptive thresholding) if needed\n    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n    extracted_text = pytesseract.image_to_string(gray, config='--psm 6')  # Use Page Segmentation Mode 6 for single block of text\n    return extracted_text.strip()\nret = True\nwhile ret:\n    ret, img = cap.read()\n    img = imutils.resize(img, height=500)",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "os.environ['TF_FORCE_GPU_ALLOW_GROWTH']",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\nnet = cv2.dnn.readNet(\"yolov3-custom_7000.weights\", \"yolov3-custom.cfg\")\nnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\nnet.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\nmodel = load_model('helmet-nonhelmet_cnn.h5')\nprint('model loaded!!!')\ncap = cv2.VideoCapture('helmet.mp4')\nCOLORS = [(0,255,0),(0,0,255)]\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "net = cv2.dnn.readNet(\"yolov3-custom_7000.weights\", \"yolov3-custom.cfg\")\nnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\nnet.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\nmodel = load_model('helmet-nonhelmet_cnn.h5')\nprint('model loaded!!!')\ncap = cv2.VideoCapture('helmet.mp4')\nCOLORS = [(0,255,0),(0,0,255)]\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "model = load_model('helmet-nonhelmet_cnn.h5')\nprint('model loaded!!!')\ncap = cv2.VideoCapture('helmet.mp4')\nCOLORS = [(0,255,0),(0,0,255)]\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "cap",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "cap = cv2.VideoCapture('helmet.mp4')\nCOLORS = [(0,255,0),(0,0,255)]\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "COLORS",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "COLORS = [(0,255,0),(0,0,255)]\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "layer_names",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "layer_names = net.getLayerNames()\noutput_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)\n        helmet_roi = helmet_roi/255.0",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "output_layers",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)\n        helmet_roi = helmet_roi/255.0\n        return int(model.predict(helmet_roi)[0][0])",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "fourcc",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nwriter = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)\n        helmet_roi = helmet_roi/255.0\n        return int(model.predict(helmet_roi)[0][0])\n    except:",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "writer = cv2.VideoWriter('output.avi', fourcc, 5,(888,500))\ndef helmet_or_nohelmet(helmet_roi):\n    try:\n        helmet_roi = cv2.resize(helmet_roi, (224, 224))\n        helmet_roi = np.array(helmet_roi,dtype='float32')\n        helmet_roi = helmet_roi.reshape(1, 224, 224, 3)\n        helmet_roi = helmet_roi/255.0\n        return int(model.predict(helmet_roi)[0][0])\n    except:\n        pass",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "ret",
        "kind": 5,
        "importPath": "detect",
        "description": "detect",
        "peekOfCode": "ret = True\nwhile ret:\n    ret, img = cap.read()\n    img = imutils.resize(img, height=500)\n    height, width = img.shape[:2]\n    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n    net.setInput(blob)\n    outs = net.forward(output_layers)\n    confidences = []\n    boxes = []",
        "detail": "detect",
        "documentation": {}
    },
    {
        "label": "voicebuzzer",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def voicebuzzer():\n    engine.say('crime detected')\n    engine.runAndWait()\ndef run_helmet_detection():\n    #subprocess.Popen(['python', 'detect.py'])\n    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n    net = cv2.dnn.readNet(\"yolov3-custom_7000.weights\", \"yolov3-custom.cfg\")\n    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n    model = load_model('helmet-nonhelmet_cnn.h5')",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_helmet_detection",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def run_helmet_detection():\n    #subprocess.Popen(['python', 'detect.py'])\n    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n    net = cv2.dnn.readNet(\"yolov3-custom_7000.weights\", \"yolov3-custom.cfg\")\n    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n    model = load_model('helmet-nonhelmet_cnn.h5')\n    print('model loaded!!!')\n    cap = cv2.VideoCapture('helmet.mp4')\n    COLORS = [(0,255,0),(0,0,255)]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_one_way_detection",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def run_one_way_detection():\n    #subprocess.Popen(['python', 'oneway.py'])\n    # Load YOLOv3 model and configuration files for vehicle detection\n    net = cv2.dnn.readNet(\"person.weights\", \"person.cfg\")\n    classes = []\n    with open(\"coco.names\", \"r\") as f:\n        classes = [line.strip() for line in f.readlines()]\n    # Define the vehicle classes we want to detect\n    vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\", \"bicycle\"]\n    # Function to calculate the direction of movement",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_weapon_detection",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def run_weapon_detection():\n    #subprocess.Popen(['python', 'weapondetection.py'])\n    net = cv2.dnn.readNet(\"savedmodel/yolo_training_2000.weights\", \"savedmodel/yolo.cfg\")\n    classes = [\"Weapon\"]\n    layer_names = net.getLayerNames()\n    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n    count=0\n    engine.say(\"Weapon detection activated\")\n    engine.runAndWait()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "engine",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "engine = pyttsx3.init()\ndef voicebuzzer():\n    engine.say('crime detected')\n    engine.runAndWait()\ndef run_helmet_detection():\n    #subprocess.Popen(['python', 'detect.py'])\n    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n    net = cv2.dnn.readNet(\"yolov3-custom_7000.weights\", \"yolov3-custom.cfg\")\n    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "root = tk.Tk()\nroot.title(\"Smart City Traffic Observation\")\n# Load and display background image\nbg_image = Image.open(\"background.png\")\nbg_image = bg_image.resize((800, 600), Image.ANTIALIAS)\nbg_photo = ImageTk.PhotoImage(bg_image)\nbg_label = tk.Label(root, image=bg_photo)\nbg_label.place(x=0, y=0, relwidth=1, relheight=1)\n# Create header label\nheader_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "bg_image",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "bg_image = Image.open(\"background.png\")\nbg_image = bg_image.resize((800, 600), Image.ANTIALIAS)\nbg_photo = ImageTk.PhotoImage(bg_image)\nbg_label = tk.Label(root, image=bg_photo)\nbg_label.place(x=0, y=0, relwidth=1, relheight=1)\n# Create header label\nheader_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')\nheader_label.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n# Create buttons for running specific scripts\nhelmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "bg_image",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "bg_image = bg_image.resize((800, 600), Image.ANTIALIAS)\nbg_photo = ImageTk.PhotoImage(bg_image)\nbg_label = tk.Label(root, image=bg_photo)\nbg_label.place(x=0, y=0, relwidth=1, relheight=1)\n# Create header label\nheader_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')\nheader_label.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n# Create buttons for running specific scripts\nhelmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)\nhelmet_button.place(relx=0.5, rely=0.2, anchor=tk.CENTER)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "bg_photo",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "bg_photo = ImageTk.PhotoImage(bg_image)\nbg_label = tk.Label(root, image=bg_photo)\nbg_label.place(x=0, y=0, relwidth=1, relheight=1)\n# Create header label\nheader_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')\nheader_label.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n# Create buttons for running specific scripts\nhelmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)\nhelmet_button.place(relx=0.5, rely=0.2, anchor=tk.CENTER)\noneway_button = tk.Button(root, text=\"One Way Detection\", font=(\"Helvetica\", 16), command=run_one_way_detection)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "bg_label",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "bg_label = tk.Label(root, image=bg_photo)\nbg_label.place(x=0, y=0, relwidth=1, relheight=1)\n# Create header label\nheader_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')\nheader_label.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n# Create buttons for running specific scripts\nhelmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)\nhelmet_button.place(relx=0.5, rely=0.2, anchor=tk.CENTER)\noneway_button = tk.Button(root, text=\"One Way Detection\", font=(\"Helvetica\", 16), command=run_one_way_detection)\noneway_button.place(relx=0.5, rely=0.3, anchor=tk.CENTER)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "header_label",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "header_label = tk.Label(root, text=\"Smart City Traffic Observation\", font=(\"Helvetica\", 24), bg='white')\nheader_label.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n# Create buttons for running specific scripts\nhelmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)\nhelmet_button.place(relx=0.5, rely=0.2, anchor=tk.CENTER)\noneway_button = tk.Button(root, text=\"One Way Detection\", font=(\"Helvetica\", 16), command=run_one_way_detection)\noneway_button.place(relx=0.5, rely=0.3, anchor=tk.CENTER)\nweapon_button = tk.Button(root, text=\"Weapon Detection\", font=(\"Helvetica\", 16), command=run_weapon_detection)\nweapon_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n# Start the main event loop",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "helmet_button",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "helmet_button = tk.Button(root, text=\"Helmet Detection\", font=(\"Helvetica\", 16), command=run_helmet_detection)\nhelmet_button.place(relx=0.5, rely=0.2, anchor=tk.CENTER)\noneway_button = tk.Button(root, text=\"One Way Detection\", font=(\"Helvetica\", 16), command=run_one_way_detection)\noneway_button.place(relx=0.5, rely=0.3, anchor=tk.CENTER)\nweapon_button = tk.Button(root, text=\"Weapon Detection\", font=(\"Helvetica\", 16), command=run_weapon_detection)\nweapon_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n# Start the main event loop\nroot.mainloop()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "oneway_button",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "oneway_button = tk.Button(root, text=\"One Way Detection\", font=(\"Helvetica\", 16), command=run_one_way_detection)\noneway_button.place(relx=0.5, rely=0.3, anchor=tk.CENTER)\nweapon_button = tk.Button(root, text=\"Weapon Detection\", font=(\"Helvetica\", 16), command=run_weapon_detection)\nweapon_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n# Start the main event loop\nroot.mainloop()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "weapon_button",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "weapon_button = tk.Button(root, text=\"Weapon Detection\", font=(\"Helvetica\", 16), command=run_weapon_detection)\nweapon_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n# Start the main event loop\nroot.mainloop()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "calculate_direction",
        "kind": 2,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "def calculate_direction(prev_box, current_box):\n    # Extract centroid coordinates of previous and current bounding boxes\n    prev_centerX = prev_box[0] + prev_box[2] / 2\n    current_centerX = current_box[0] + current_box[2] / 2\n    # Determine the direction based on the change in centroid position\n    if current_centerX > prev_centerX:\n        direction = \"Coming\"\n    else:\n        direction = \"Going\"\n    return direction",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "detect_vehicles",
        "kind": 2,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "def detect_vehicles(image):\n    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n    net.setInput(blob)\n    layer_outputs = net.forward(net.getUnconnectedOutLayersNames())\n    # Initialize lists to store detected vehicles and their bounding boxes\n    vehicles = []\n    boxes = []\n    # Loop over each detection\n    for output in layer_outputs:\n        for detection in output:",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "kind": 2,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "def draw_boxes(image, vehicles, boxes, directions):\n    for (vehicle, (x, y, width, height), direction) in zip(vehicles, boxes, directions):\n        color = (0, 255, 0) if direction == \"Coming\" else (0, 0, 255)\n        cv2.rectangle(image, (x, y), (x + width, y + height), color, 2)\n        cv2.putText(image, f\"{vehicle} - {direction}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n# Function to process live camera feed\ndef process_camera_feed():\n    cap = cv2.VideoCapture(\"oneway2.mp4\")\n    ret, prev_frame = cap.read() \n    prev_vehicles, prev_boxes = [], []",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "process_camera_feed",
        "kind": 2,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "def process_camera_feed():\n    cap = cv2.VideoCapture(\"oneway2.mp4\")\n    ret, prev_frame = cap.read() \n    prev_vehicles, prev_boxes = [], []\n    while cap.isOpened():\n        ret, current_frame = cap.read()\n        if not ret:\n            break\n        current_vehicles, current_boxes = detect_vehicles(current_frame)\n        if current_vehicles and prev_vehicles:",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "net = cv2.dnn.readNet(\"person.weights\", \"person.cfg\")\nclasses = []\nwith open(\"coco.names\", \"r\") as f:\n    classes = [line.strip() for line in f.readlines()]\n# Define the vehicle classes we want to detect\nvehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\", \"bicycle\"]\n# Function to calculate the direction of movement\ndef calculate_direction(prev_box, current_box):\n    # Extract centroid coordinates of previous and current bounding boxes\n    prev_centerX = prev_box[0] + prev_box[2] / 2",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "classes",
        "kind": 5,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "classes = []\nwith open(\"coco.names\", \"r\") as f:\n    classes = [line.strip() for line in f.readlines()]\n# Define the vehicle classes we want to detect\nvehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\", \"bicycle\"]\n# Function to calculate the direction of movement\ndef calculate_direction(prev_box, current_box):\n    # Extract centroid coordinates of previous and current bounding boxes\n    prev_centerX = prev_box[0] + prev_box[2] / 2\n    current_centerX = current_box[0] + current_box[2] / 2",
        "detail": "oneway",
        "documentation": {}
    },
    {
        "label": "vehicle_classes",
        "kind": 5,
        "importPath": "oneway",
        "description": "oneway",
        "peekOfCode": "vehicle_classes = [\"car\", \"bus\", \"truck\", \"motorcycle\", \"bicycle\"]\n# Function to calculate the direction of movement\ndef calculate_direction(prev_box, current_box):\n    # Extract centroid coordinates of previous and current bounding boxes\n    prev_centerX = prev_box[0] + prev_box[2] / 2\n    current_centerX = current_box[0] + current_box[2] / 2\n    # Determine the direction based on the change in centroid position\n    if current_centerX > prev_centerX:\n        direction = \"Coming\"\n    else:",
        "detail": "oneway",
        "documentation": {}
    }
]